{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('/Users/maryammaghsoudi/course/computer_vision/openCV/data_python/DATA/00-puppy.jpg')\n",
    "img\n",
    "#in cv2 image color are like (b,g, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gray = cv2.imread('/Users/maryammaghsoudi/course/computer_vision/openCV/data_python/DATA/00-puppy.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "plt.imshow(img_gray,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img =cv2.resize(img_rgb,(1300,275))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = cv2.flip(img_rgb,0)\n",
    "plt.imshow(new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('my_new_picture.jpg',new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(img_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank_img = np.zeros(shape=(512,512,3),dtype=np.int16)\n",
    "plt.imshow(blank_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.rectangle(blank_img,pt1=(384,0),pt2=(510,128),color=(0,255,0),thickness=5)\n",
    "#cv2.circle(img=blank_img, center=(100,100), radius=50, color=(255,0,0), thickness=5)\n",
    "#filled shape cv2.circle(img=blank_img, center=(400,400), radius=50, color=(255,0,0), thickness=-1)\n",
    "#cv2.line(blank_img,pt1=(0,0),pt2=(511,511),color=(102, 255, 255),thickness=5)\n",
    "plt.imshow(blank_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "cv2.putText(blank_img, text='hello', org = (10,500), fontFace=font, fontScale=4,\n",
    "            color=(255,255,255), thickness=3, lineType=cv2.LINE_AA)\n",
    "plt.imshow(blank_img)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank_img = np.zeros(shape=(512,512,3), dtype=np.int32)\n",
    "plt.imshow(blank_img)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices = np.array([ [100,300], [200,200], [ 400,300], [200,400]], dtype= np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv2 only accepts arrays with three dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts =vertices.reshape((-1,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.polylines(blank_img, [pts], isClosed=True, color=(255,0,0), thickness= 5)\n",
    "plt.imshow(blank_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to fill the ploylines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# drwing by mouse on images:\n",
    "it is better to use python scripts of run one cell in jupyter (especially on macos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "################\n",
    "##Function######\n",
    "################\n",
    "def draw_circle(event, x, y, flags, param):\n",
    "    # the event is the left botton of mouse is clicked down\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        cv2.circle(img, (x,y), radius=100, color=(0,255,0), thickness=  -1)\n",
    "\n",
    "\n",
    "    elif event== cv2.EVENT_RBUTTONDOWN:\n",
    "        cv2.circle(img, (x,y), radius=100, color=(255,0,0), thickness=  -1)\n",
    "\n",
    "    \n",
    "\n",
    "cv2.namedWindow(winname='my_drwing')\n",
    "cv2.setMouseCallback('my_drwing', draw_circle)\n",
    "\n",
    "################\n",
    "#Showing image with openCV#\n",
    "################\n",
    "\n",
    "img = np.zeros (shape=(512, 512,3), dtype= np.int8)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow( 'my_drwing', img)\n",
    "    if cv2.waitKey(20) & 0XFF==27: # if the esc key is prssed\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "# variables\n",
    "# true while mouse button  down, false while mouse botton up\n",
    "drawing = False\n",
    "ix, iy= -1, -1\n",
    "#function\n",
    "def draw_rectangle(event, x,y, flags, params):\n",
    "    global ix, iy, drawing\n",
    "    if event==cv2.EVENT_FLAG_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        ix, iy =x,y\n",
    "    elif event== cv2.EVENT_MOUSEMOVE:\n",
    "        if drawing ==True:\n",
    "            cv2.rectangle(img, (ix, iy), (x,y), (0,255,0), -1)\n",
    "    elif event== cv2.EVENT_FLAG_LBUTTONUP:\n",
    "\n",
    "        drawing =False\n",
    "        cv2.rectangle(img, (ix,iy),(0,255,0), -1)\n",
    "\n",
    "     \n",
    "    pass\n",
    "\n",
    "#showing the image\n",
    "\n",
    "img = np.zeros((512,512,3))\n",
    "cv2.namedWindow(winname='my_drawing')\n",
    "cv2.setMouseCallback('my_drawing     ')\n",
    "while True:\n",
    "    cv2.imshow('my_drawing', img)\n",
    "    if cv2.waitKey(1) & 0xFF==27:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# color spacing with cv2 <br>\n",
    "hsv = hue sturation value <br>\n",
    "hls = hue  lightness saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img= cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "plt.imshow(img)\n",
    "# but because this image is not capable with HLS or HSV the below image we see do not make sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blending and pasting multiple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2. imread('/Users/maryammaghsoudi/Course/computer_vision/openCV/data_python/DATA/dog_backpack.jpg')\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "img2 = cv2.imread('/Users/maryammaghsoudi/Course/computer_vision/openCV/data_python/DATA/watermark_no_copy.png')\n",
    "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blending images of the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.resize(img1, (1200,1200))\n",
    "img2 = cv2.resize(img2, (1200, 1200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for same size images\n",
    "blended= cv2.addWeighted(src1= img1, alpha=0.7, src2=img2, beta=0.3 , gamma=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(blended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### overlay small image on top of a larger image (no Blending)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = cv2.resize(img2, (600,600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### blend together images of different size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_img = img1\n",
    "small_img = img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_offset = 0\n",
    "y_offset= 0\n",
    "\n",
    "x_end = x_offset+small_img.shape[1]\n",
    "y_end = y_offset+small_img.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_img[y_offset:y_end, x_offset:x_end] =small_img\n",
    "plt.imshow(large_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### blenading and pasting some part of an image on other image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2. imread('/Users/maryammaghsoudi/Course/computer_vision/openCV/data_python/DATA/dog_backpack.jpg')\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "img2 = cv2.imread('/Users/maryammaghsoudi/Course/computer_vision/openCV/data_python/DATA/watermark_no_copy.png')\n",
    "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "img2 = cv2.resize(img2, (600,600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_offset = 934-600\n",
    "y_offset = 1401 -600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols, channels = img2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi (region of interest)\n",
    "roi = img1[y_offset:1401, x_offset:934 ]\n",
    "plt.imshow(roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2grey = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
    "plt.imshow(img2grey, cmap= 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_inv = cv2.bitwise_not(img2grey)\n",
    "plt.imshow(mask_inv, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_background = np.full(img2.shape,255, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bk = cv2.bitwise_or(white_background,white_background, mask=mask_inv )\n",
    "plt.imshow(bk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = cv2.bitwise_or(img2, img2, mask=mask_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_roi = cv2.bitwise_or(roi, fg)\n",
    "plt.imshow(final_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_offset+small_img.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_roi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_img[600: 600+small_img.shape[0],600: 600+small_img.shape[1]] = final_roi\n",
    "plt.imshow(large_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image thresholding <br>\n",
    "thresholding will convert an image to consist of only two values, white or black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by adding zero as parameter in imread function, the image is been read as grayscale\n",
    "img = cv2.imread('/Users/maryammaghsoudi/Course/computer_vision/openCV/data_python/DATA/rainbow.jpg', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any value below the threshold turn into zero and any value above the threshold will be turn into maxval\n",
    "# typically what you do for thresholding in a lots of situations is you just choose the helfway point (255/2)\n",
    "# The first argument is the source image, which should be a grayscale image.\n",
    "ret, thresh1 = cv2.threshold(src=img, thresh= 127, maxval=255,type= cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(thresh1, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('/Users/maryammaghsoudi/Course/computer_vision/openCV/data_python/DATA/crossword.jpg', 0)\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_show(img):\n",
    "    fig =plt.figure(figsize=(15,15))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img, cmap='gray')\n",
    "\n",
    "img_show(img=img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when this happen and we lose some quality we can use  other kind of threshold type or we can \n",
    "# change our maxvalue or threshold value\n",
    "ret,th1 = cv2.threshold(img, 127, 255,cv2.THRESH_BINARY)\n",
    "img_show(th1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the previous section, we used one global value as a threshold. But this might not be good in all cases, e.g. if an \n",
    "#image has different lighting conditions in different areas. In that case, adaptive thresholding can help. Here, the algorithm \n",
    "#determines the threshold for a pixel based on a small region around it.\n",
    "#So we get different thresholds for different regions of the same image which gives better results for images with varying illumination\n",
    "th2 = cv2.adaptiveThreshold(src=img, maxValue=255,adaptiveMethod= cv2.ADAPTIVE_THRESH_MEAN_C, thresholdType=cv2.THRESH_BINARY,\n",
    "                            blockSize=11, C=8)\n",
    "img_show(th2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gamma\tscalar added to each sum\n",
    "belnaded = cv2.addWeighted(src1=th1, alpha=0.6, src2=th2, beta=0.4, gamma=0)\n",
    "img_show(belnaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# blurring and smoothing <br>\n",
    "it is useful for edge detection\n",
    "in bluring image with kernel one  each pixel of imge is been replaced with the multiply and sum of a matrix in that pixel and the neighor pixels<br>\n",
    "https://setosa.io/ev/image-kernels/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img():\n",
    "    img= cv2.imread('/Users/maryammaghsoudi/Course/computer_vision/openCV/data_python/DATA/bricks.jpg').astype(np.float32)/255\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "def display_img (img):\n",
    "    fig = plt.figure(figsize=(12,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img(load_img())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## increasing and decreasing image brightness\n",
    "Gamma correction is also known as the Power Law Transform. First, our image pixel intensities must be scaled from the range [0, 255] to [0, 1.0]. From there, we obtain our output gamma corrected image by applying the following equation:\n",
    "\n",
    "O = I ^ (1 / G)\n",
    "\n",
    "Where I is our input image and G is our gamma value. The output image O is then scaled back to the range [0, 255].\n",
    "\n",
    "Gamma values < 1 will shift the image towards the darker end of the spectrum while gamma values > 1 will make the image appear lighter. A gamma value of G=1 will have no affect on the input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1/4\n",
    "result=np.power(load_img(), gamma)\n",
    "display_img(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picture = load_img()\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "cv2.putText(picture , text='bircks', org = (10,600), fontFace=font, fontScale=10,\n",
    "            color=(255,0,0), thickness=4)\n",
    "\n",
    "display_img(picture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones(shape=(5,5), dtype=np.float32)/25\n",
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bluring n\n",
    "#depth – Depth of the output image  -1 will give the output image depth as same as the input image]\n",
    "dst = cv2.filter2D(picture, -1, kernel)\n",
    "display_img(dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gausian blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blured_img = cv2.GaussianBlur(src=picture,ksize= (5,5), sigmaX=10)\n",
    "display_img(blured_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Median Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in medianBlur the  kernel is squera so we must choose and an integr like 5 which means  (5,5)\n",
    "blr_img = cv2.medianBlur(src=picture, ksize=5)\n",
    "display_img(blured_img  )\n",
    "# meadiablur is very good at removing the nosie  and kept the main essential details\n",
    "# this make medianBlur as interesting technique for removing noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sammy = cv2.imread('/Users/maryammaghsoudi/Course/computer_vision/openCV/data_python/DATA/sammy_noise.jpg')\n",
    "#sammy = cv2.cvtColor(sammy, cv2.COLOR_BGR2RGB)\n",
    "display_img(sammy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_noise_sammy = cv2.medianBlur(sammy, 5)\n",
    "display_img(no_noise_sammy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# morphological Operatinos <br>\n",
    "are sets of kernels that can achieve a variety of effects, such as reducing noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img():\n",
    "    blanck_img = np.zeros((600,600))\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(blanck_img, text='ABCDE', org=(50,300), fontFace=font, fontScale=5, \n",
    "                color=(255,255, 255), thickness=30)\n",
    "    return blanck_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_img(img):\n",
    "    fig = plt.figure(figsize=(12,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img(load_img())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### erosion: it erode away the boundaries of the foreground objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5,5), dtype=np.uint8)\n",
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eroded_img = cv2.erode(load_img(), kernel, iterations=4)\n",
    "display_img(eroded_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dilation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_noise = np.random.randint(low=0, high=2, size=(600,600))\n",
    "white_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img(white_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_img().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_noise = white_noise * 255\n",
    "display_img(white_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_img = white_noise + load_img()\n",
    "display_img(noise_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful for removing background noise\n",
    "opening = cv2.morphologyEx(noise_img, cv2.MORPH_OPEN, kernel)\n",
    "display_img(opening)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we are going to make some forground noise\n",
    "black_noise = np.random.randint(low=0, high=2, size=(600,600))\n",
    "black_noise = black_noise*(-255)\n",
    "#this noise will affect the white color and do not change the black color of the background\n",
    "black_noise_img = load_img()+black_noise\n",
    "#but this does not make sense and eahc of our values must be  between 0 and 255\n",
    "#black_noise_img [black_noise_img== -255] =0\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_noise_img.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img(black_noise_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_noise_img.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closing = cv2.morphologyEx(black_noise_img, cv2.MORPH_CLOSE, kernel) \n",
    "display_img(closing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient is a somthing between erosion and dilation and it can be used for edge detection\n",
    "gradient = cv2.morphologyEx(load_img(),cv2.MORPH_GRADIENT, kernel)\n",
    "display_img(gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradients:\n",
    "gradient is an extesnion for morphological operators nad undestanding gradinets will eventually lead us to understanding edge detection, which allow us to perform operations such as abject detection, object tracking  and eventually even image classification <br>\n",
    "an image gradient is a directional change in the intensity or color is an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobel- Feldman Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_img(img):\n",
    "    fig = plt.figure(figsize=(12,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sukodo = cv2.imread('/Users/maryammaghsoudi/Course/computer_vision/openCV/data_python/DATA/sudoku.jpg', 0)\n",
    "display_img(sukodo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobelx = cv2.Sobel(sukodo, cv2.CV_64F,1,0   ,5)\n",
    "display_img(sobelx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobely = cv2.Sobel(sukodo, cv2.CV_64F,0,1   ,5)\n",
    "display_img(sobely)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## laplacian derivatie:\n",
    "it claculate the derivates in both x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplasian = cv2.Laplacian(sukodo,cv2.CV_64F)\n",
    "display_img(laplasian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended = cv2.addWeighted(src1= sobelx,alpha = 0.5, src2 =sobely, beta = 0.5, gamma=0 )\n",
    "display_img(blended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, th1 = cv2.threshold(sukodo, 100,255, cv2.THRESH_BINARY)\n",
    "display_img(th1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((4,4), np.uint8)\n",
    "gradient = cv2.morphologyEx(blended, cv2.MORPH_GRADIENT, kernel)\n",
    "display_img(gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# histograms: <br>\n",
    "for images, we can display hte frequency of values for colors.<br>\n",
    "each of the three RGB channels has values betwee n0 -255. <br>\n",
    "we can plot these as 3 histogram on top of each other to see how much of each channel there is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_horse = cv2.imread('/Users/maryammaghsoudi/Course/computer_vision/openCV/data_python/DATA/horse.jpg')\n",
    "show_horse = cv2.cvtColor(dark_horse, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "rainbow = cv2.imread('/Users/maryammaghsoudi/Course/computer_vision/openCV/data_python/DATA/rainbow.jpg')\n",
    "show_rainbow = cv2.cvtColor(rainbow, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "blue_bricks = cv2.imread('/Users/maryammaghsoudi/Course/computer_vision/openCV/data_python/DATA/bricks.jpg')\n",
    "show_bricks = cv2.cvtColor(blue_bricks, cv2.COLOR_BGR2RGB) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask, for when you want to mask part of the image and only calculate the \n",
    "# histogram for that part of the image\n",
    "# histsize, give you the upper limit\n",
    "# ranges is exclusive\n",
    "# this is the histogram for the blue color\n",
    "hist_values = cv2.calcHist([dark_horse], channels=[0], mask =None, histSize =[256], ranges=[0,256])\n",
    "hist_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img =dark_horse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "color = ('b', 'g','r')\n",
    "for i, col in enumerate(color):\n",
    "    hists = cv2.calcHist([img], channels=[i], mask =None, histSize =[256], ranges=[0,256])\n",
    "    plt.plot(hists, color= col)\n",
    "    plt.xlim([0,50])\n",
    "    plt.ylim([0,500000])\n",
    "\n",
    "plt.title('histogram for blue bricks')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## histograms on a masked portion of the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram Equalization (increasing contrast): \n",
    "is a method of contrast adjustmnet based on the image's histogram. \n",
    "we're going to apply histogram equalization, which is going to reduce the color depth. what we mean by reducing the color depth, is you're going to reduce the shades of gray. and we flatten the histogram and making thta cumulative histogram more linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainbow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros(rainbow.shape[:2], np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(mask, cmap='gray')\n",
    "mask[300:400, 100:400]=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(show_rainbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_rainbow = cv2.bitwise_and(show_rainbow, show_rainbow, mask=mask)\n",
    "plt.imshow(mask_rainbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_mask_values_red = cv2.calcHist([rainbow], channels=[2], mask= mask, histSize =[256], ranges = [0,256]  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist_mask_values_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gorilla = cv2.imread('/Users/maryammaghsoudi/Course/computer_vision/openCV/data_python/DATA/gorilla.jpg',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img(gorilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gorilla.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gorilla_hist = cv2.calcHist([gorilla],channels=[0], mask= None,\n",
    "                            histSize = [256], ranges=[0,256])\n",
    " \n",
    "plt.plot(gorilla_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the contrast inreased here\n",
    "eq_gorilla =  cv2.equalizeHist(gorilla)\n",
    "display_img(eq_gorilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_gorilla_hist = cv2.calcHist([eq_gorilla],channels=[0], mask= None,\n",
    "                            histSize = [256], ranges=[0,256])\n",
    " \n",
    "plt.plot(eq_gorilla_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_gorilla = cv2.imread('/Users/maryammaghsoudi/Course/computer_vision/openCV/data_python/DATA/gorilla.jpg')\n",
    "\n",
    "# if we want to use equalization for a color image we must first convert it into hse\n",
    "hsv_gorilla = cv2.cvtColor(color_gorilla, cv2.COLOR_BGR2HSV)\n",
    "# this shows the channels of the image (hue,sturation, value)\n",
    "hsv_gorilla [:,:,2] =cv2.equalizeHist(hsv_gorilla [:,:,2])\n",
    "\n",
    "color_gorilla_eq = cv2.cvtColor(hsv_gorilla,cv2.COLOR_HSV2RGB)\n",
    "display_img(color_gorilla_eq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_gorilla_hist_color = cv2.calcHist([color_gorilla_eq],channels=[0], mask= None,\n",
    "                            histSize = [256], ranges=[0,256])\n",
    " \n",
    "plt.plot(eq_gorilla_hist_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
